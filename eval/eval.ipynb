{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalkerhowell3/miniconda3/envs/ca-gnn-marl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from make_env import make_env\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../mpe')\n",
    "from modules.agents import *\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import re\n",
    "import importlib\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictView(object):\n",
    "        def __init__(self, d):\n",
    "            self.__dict__ = d\n",
    "        def __str__(self):\n",
    "             \n",
    "             return(str(self.__dict__))\n",
    "\n",
    "def load_experiment(experiment_dir, run_index, env, results_rel_dir=\"results\"):\n",
    "    \"\"\"Load the sacred config and find the model path\"\"\"\n",
    "    sacred_dir = os.path.join(experiment_dir, results_rel_dir, \"sacred_runs\", env.split(\":\")[-1], str(run_index))\n",
    "    with open(os.path.join(sacred_dir, \"config.json\"), 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        \n",
    "        config = DictView(config)\n",
    "    # find the models path and tensor board path\n",
    "    unique_token=config.unique_token\n",
    "    models_dir = os.path.join(experiment_dir, results_rel_dir, \"models\", env, unique_token, str(run_index))\n",
    "    tb_dir = os.path.join(experiment_dir, \"results\", \"tb_logs\", env, unique_token, str(run_index))\n",
    "    \n",
    "    return config, models_dir, tb_dir\n",
    "\n",
    "def load_model(models_dir, config):\n",
    "\n",
    "    # find the last checkpoint\n",
    "    ckts = [int(re.sub(\"[^0-9]\", \"\", ckt) if len(re.sub(\"[^0-9]\", \"\", ckt)) > 0 else str(-1)) for ckt in os.listdir(models_dir)]\n",
    "    print(\"Loading model checkpoint: \", str(max(ckts)))\n",
    "    ckt = max(ckts)\n",
    "\n",
    "    model_file = os.path.join(models_dir, str(ckt), 'agent.th')\n",
    "    model_weights = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    input_dim = model_weights[list(model_weights.keys())[0]].shape[1]\n",
    "    \n",
    "    if config.agent=='mlp':\n",
    "        model = MLPAgent(input_dim, config)\n",
    "    elif config.agent=='rnn':\n",
    "        model = RNNAgent(input_dim, config)\n",
    "    elif config.agent == 'gnn':\n",
    "        model = GNNAgent(input_dim, config)\n",
    "    model.load_state_dict(model_weights)\n",
    "    # model.eval()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(env_name, model, config, env_config):\n",
    "    # env = make_env(env_name)\n",
    "    if(env_name == \"robotarium_gym:HeterogeneousSensorNetwork-v0\"):\n",
    "        env_module = importlib.import_module(f'robotarium_gym.scenarios.HeterogeneousSensorNetwork.HeterogeneousSensorNetwork')\n",
    "        env_class = getattr(env_module, \"HeterogeneousSensorNetwork\")\n",
    "        env_config = DictView(env_config)\n",
    "        env = env_class(env_config)\n",
    "\n",
    "    obs = np.array(env.reset())\n",
    "    n_agents = len(obs)\n",
    "    \n",
    "    totalReturn = []\n",
    "    totalConnectivity = []\n",
    "    totalSteps = []\n",
    "    totalViolations = []\n",
    "    totalOverlap = []\n",
    "    \n",
    "    max_edges = n_agents * (n_agents - 1) / 2.0\n",
    "    \n",
    "    for i in tqdm(range(env_config.episodes)):\n",
    "        episodeReturn = 0\n",
    "        episodeSteps = 0\n",
    "        episodeViolations = 0\n",
    "        episodeConnectivity = [0 for _ in range(int(max_edges+1))]\n",
    "        episodeOverlap = []\n",
    "        hs = np.array([np.zeros((config.hidden_dim, )) for i in range(n_agents)])\n",
    "        \n",
    "        for j in range(env_config.max_episode_steps+1):      \n",
    "            \n",
    "            if config.agent == \"gnn\":\n",
    "                q_values, hs = model(torch.Tensor(obs), torch.Tensor(env.adj_matrix))\n",
    "            else:\n",
    "                q_values, hs = model(torch.Tensor(obs), torch.Tensor(hs))\n",
    "              \n",
    "            actions = np.argmax(q_values.detach().numpy(), axis=1)\n",
    "\n",
    "            obs, reward, done, info = env.step(actions)\n",
    "            \n",
    "            # log data\n",
    "            episodeViolations += 1.0 if info[\"violation_occurred\"] else 0.0\n",
    "            episodeConnectivity[info[\"connectivity\"]] += 1\n",
    "            episodeOverlap.append(info[\"total_overlap\"])\n",
    "\n",
    "            if env_config.shared_reward:\n",
    "                episodeReturn += reward[0]\n",
    "            else:\n",
    "                episodeReturn += sum(reward)\n",
    "            if done[0]:\n",
    "                episodeSteps = j+1\n",
    "                break\n",
    "        \n",
    "        if episodeSteps == 0:\n",
    "            episodeSteps = env_config.max_episode_steps\n",
    "        \n",
    "        obs = np.array(env.reset())\n",
    "        totalReturn.append(episodeReturn)\n",
    "        totalSteps.append(episodeSteps)\n",
    "        totalConnectivity.append(list(np.array(episodeConnectivity)/episodeSteps))\n",
    "        totalViolations.append(episodeViolations)\n",
    "        totalOverlap.append(np.mean(episodeOverlap))\n",
    "    \n",
    "\n",
    "    eval_data_dict = {\n",
    "        \"returns\": totalReturn,\n",
    "        \"steps\": totalSteps,\n",
    "        \"violations\": totalViolations,\n",
    "        \"connectivity\": totalConnectivity,\n",
    "        \"overlap\": totalOverlap\n",
    "    }\n",
    "    return(eval_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model checkpoint:  20471292\n",
      "##### DEBUG OUTPUT #####\n",
      "Your simulation will take approximately 1 real seconds when deployed on the Robotarium. \n",
      "\n",
      "\t Simulation had 2040 iteration(s) where the actuator limits were exceeded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 67/1000 [00:30<06:51,  2.27it/s]"
     ]
    }
   ],
   "source": [
    "environment = \"robotarium_gym:HeterogeneousSensorNetwork-v0\"\n",
    "experiment_dir = \"/home/dwalkerhowell3/star_lab/experiments_ca-gnn-marl/SC_4_agents_HSN\"\n",
    "env_config_dir = \"/home/dwalkerhowell3/star_lab/experiments_ca-gnn-marl/eval_env_configs\" # this is the where \"config.yamls\" for the robotarium environment are located\n",
    "save_eval_result_dir = \"/home/dwalkerhowell3/star_lab/experiments_ca-gnn-marl/eval_saves\"\n",
    "env_config_filename = \"eval_4_agents_unseen.yaml\"\n",
    "\n",
    "##################\n",
    "sacred_run = 1\n",
    "save_filename = \"eval_4_agents_unseen_SC_4_agents_seed_1.json\"\n",
    "################\n",
    "\n",
    "env_config_file = os.path.join(env_config_dir, env_config_filename)\n",
    "config, model_dir, tb_dir = load_experiment(experiment_dir, sacred_run, environment, results_rel_dir=\"results_seed_1\")\n",
    "config.n_actions = 5\n",
    "model = load_model(model_dir, config)\n",
    "\n",
    "# load the environment config\n",
    "with open(env_config_file, 'r') as f:\n",
    "    env_config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "config.n_agents = env_config[\"n_agents\"]\n",
    "\n",
    "eval_output_dict = run_eval(environment, model, config, env_config)\n",
    "\n",
    "with open(os.path.join(save_eval_result_dir, save_filename), 'w') as f:\n",
    "    json.dump(eval_output_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca-gnn-marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2102737bb5e2ebcaf75a3d876b0dad3d3a0efd90a59889d618fc7fea7c30d47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
